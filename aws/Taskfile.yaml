# https://taskfile.dev
# Taskfile for automating AWS EKS, ArgoCD deployment and destruction

version: '3'

#TODO - "captain" and "admiral" are hardcoded throughout

vars:
  GREETING: "Time to deploy some EKS Clusters the GlueOps way!"
env:
  TF_VAR_COMPANY_KEY: 
    sh: echo -n $COMPANY_KEY
  AWS_ACCESS_KEY_ID:
    sh: echo -n $AWS_ACCESS_KEY_ID
  AWS_SECRET_ACCESS_KEY:
    sh: echo -n $AWS_SECRET_ACCESS_KEY
  AWS_REGION:
    sh: echo -n $AWS_REGION
  ADMIRAL_ACCOUNT_ID:
    sh: echo -n $(aws organizations list-accounts | jq '.Accounts | .[] | select(.Name | contains("admiral")) | .Id' | tr -d '"')
  CAPTAIN_ACCOUNT_ID:
    sh: echo -n $(aws organizations list-accounts | jq '.Accounts | .[] | select(.Name | contains("captain")) | .Id' | tr -d '"')
  SVC_LB_PATCH:
    sh: echo -n '{"spec"'':' '{"type"'':'  '"LoadBalancer"}}'
  


tasks:
  default:
    desc: Shows a list of all tasks
    cmds:
      - task -a

  test:
    cmds:
      - echo {{.GREETING}}
  
  configs:
    desc: Generate configs
    cmds:
      - envsubst < ../shared/application-definition-for-apps-cluster.yaml.tpl > ../shared/application-definition-for-apps-cluster.yaml
      - rm -rf ~/.aws/ && mkdir ~/.aws
      - envsubst < ./config.tpl > ~/.aws/config

  eks_up:
    desc: Deploy Admiral and Captain AWS EKS clusters
    cmds:
      - date >> run.txt
      - terraform init
      - terraform apply --auto-approve
      - terraform apply
      - date >> run.txt

  eks_bootstrap_argocd:
    desc: install argocd on admiral cluster
    cmds:
      # Set Admiral Cluster kubeconfig
      - rm -rf ~/.kube/
      - aws eks update-kubeconfig --region us-west-2 --name test-nonprod-test-stage-test-name-cluster --profile admiral --role-arn arn:aws:iam::{{.ADMIRAL_ACCOUNT_ID}}:role/OrganizationAccountAccessRole
      - kubectl config rename-context `kubectl config current-context` {{.TF_VAR_COMPANY_KEY}}-admiral
      - mv ~/.kube/config ~/.kube/admiral

      # Set Captain Cluster kubeconfig
      - aws eks update-kubeconfig --region us-west-2 --name test-nonprod-test-stage-test-name-cluster --profile captain --role-arn arn:aws:iam::{{.CAPTAIN_ACCOUNT_ID}}:role/OrganizationAccountAccessRole
      - kubectl config rename-context `kubectl config current-context` {{.APPS_CLUSTER_NAME}}
      - mv ~/.kube/config ~/.kube/apps

      # Create combined kubeconfig
      - KUBECONFIG={{.HOME}}/.kube/admiral:{{.HOME}}/.kube/apps kubectl config view --flatten > /tmp/config && mv /tmp/config ~/.kube/config
      - rm ~/.kube/admiral ~/.kube/apps
      
      # Deploy ArgoCD 
      - kubectl config use-context {{.TF_VAR_COMPANY_KEY}}-admiral
      - kubectl create namespace argocd || true
      - kubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/v2.4.11/manifests/install.yaml
      - kubectl wait pods --all -n argocd --for condition=Ready --timeout=120s
      - kubectl patch svc argocd-server -n argocd -p {{shellQuote .SVC_LB_PATCH}}
      
      # Log in to ArgoCD on Admiral Cluster
      - until argocd login $(kubectl get service argocd-server -n argocd --output=jsonpath="{.status.loadBalancer.ingress[0].hostname}") --username admin --password $(kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath="{.data.password}" | base64 -d; echo) --grpc-web --insecure; do echo "" ; done
      
      # Add Captain cluster to Admiral Cluster (from login above) from captain cluster context
      - argocd cluster add {{.APPS_CLUSTER_NAME}} --grpc-web --yes
      - kubectl apply -f ../shared/admiral-argocd-health-check.yaml -n argocd

  eks_bootstrap_apps_cluster:
    desc: Using the ADMIRAL, install an argo app to bootstrap the apps cluster
    cmds:
      - kubectl config use-context {{.TF_VAR_COMPANY_KEY}}-admiral
      - kubectl apply -f ../shared/application-definition-for-apps-cluster.yaml -n argocd

  get_argocd_logins:
    desc: get logins for argocd
    cmds:
      - rm -rf credentials.txt
      - kubectl config use-context {{.TF_VAR_COMPANY_KEY}}-admiral
      - echo 'Admiral Server:' 'https://'$(kubectl get service argocd-server -n argocd --output=jsonpath="{.status.loadBalancer.ingress[0].hostname}") >> credentials.txt && echo 'User:' 'admin' >> credentials.txt  && echo 'Password:' $(kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath="{.data.password}" | base64 -d) >> credentials.txt
      - kubectl config use-context {{.APPS_CLUSTER_NAME}}
      - echo 'Apps Server:' 'https://'$(kubectl get ing -n glueops-core -o=jsonpath="{$.items[0].spec.rules[0].host}") >> credentials.txt && echo 'User:' 'admin' >> credentials.txt  && echo 'Password:' $(kubectl -n glueops-core get secret argocd-initial-admin-secret -o jsonpath="{.data.password}" | base64 -d) >> credentials.txt

  clean:
    desc: Nuke all AWS resources and delete temporary configuration files
    #TODO
    vars:
      FOLDER_ID:
        sh: gcloud resource-manager folders list --organization=`gcloud organizations list --format=json | jq -r '.[0].name | split("/") | .[1]'` --filter="{{.TF_VAR_COMPANY_KEY}} Core" --format=json | jq -r '.[0].name | split("/") | .[1]' || true
    cmds:
      - gcloud projects delete {{.TF_VAR_COMPANY_KEY}}-apps-{{.TF_VAR_TEST_NUMBER}} --quiet || true
      - gcloud projects delete {{.TF_VAR_COMPANY_KEY}}-admiral-{{.TF_VAR_TEST_NUMBER}} --quiet || true
      - gcloud alpha billing projects unlink {{.TF_VAR_COMPANY_KEY}}-apps-{{.TF_VAR_TEST_NUMBER}} || true
      - gcloud alpha billing projects unlink {{.TF_VAR_COMPANY_KEY}}-admiral-{{.TF_VAR_TEST_NUMBER}} || true
      - gcloud resource-manager folders update {{.FOLDER_ID}} --display-name=`date +%s`"-DELETED" || true
      - rm -rf *terraform*
      - rm -rf .terraform*
      - rm -rf ~/.kube/
      - rm -rf credentials.txt
      - rm -rf ~/.aws/
      